{"cells":[{"cell_type":"code","source":["'''\nPROBLEM STATEMENT\n\nBuild a data pipeline with the files supplied to be served in an relational schema format.\nSource : Could be any file system, for the purpose of this POC , I'm keeping the files in local storage(DBFS).\nTarget : Would be a relational database, I need to create a connection to that database in this POC.\n'''"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4405508-9d8e-488d-ba41-ab44e0e455eb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructField, StructType, StringType, IntegerType,DoubleType\n\nschema_location = StructType([StructField(\"sr_no\", IntegerType(), True)\n                              ,StructField(\"id\", IntegerType(), True)\n                              ,StructField(\"wgs84_polygon\", StringType()\n                                           ,True)])\n                              \nschema_reservations = StructType([StructField(\"sr_no\", IntegerType(), True)\n                                  ,StructField(\"id\", IntegerType(), True)\n                                  ,StructField(\"customer_id\", StringType(), True)\n                                  ,StructField(\"start_latitude\", StringType(), True)\n                                  ,StructField(\"start_longitude\", StringType(), True)\n                                  ,StructField(\"srid\", StringType(), True)\n                                  ,StructField(\"net_price\", DoubleType(),True)\n                                 ])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Importing important libraries and defining schema","showTitle":true,"inputWidgets":{},"nuid":"5f073234-0ec1-4ad4-9716-c6450d0ccddc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["df_loc = spark.read.format(\"csv\").options(header = 'true').schema(schema_location).load(\"/FileStore/tables/felyxData/assignment_locations.csv\")\ndf_resv = spark.read.format(\"csv\").options(header = 'true').schema(schema_reservations).load(\"/FileStore/tables/felyxData/assignment_reservations.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Building dataframe","showTitle":true,"inputWidgets":{},"nuid":"c0602078-499a-495a-8368-b9c5b7d18366"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["jdbcUrl = \"jdbc:sqlserver://mysqlserver057.database.windows.net:1433;database=mysqldb\"\nconnectionProperties = {\n  \"user\" : \"ashish\",\n  \"password\" : \"******\",\n  \"driver\" : \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n}\n\ntry:\n  df_loc.write.jdbc(url=jdbcUrl, table=\"dbo.location\",mode = \"overwrite\", properties=connectionProperties )\nexcept ValueError as error :\n  print(\"Connector write failed\", error)\n    \ntry:\n  df_resv.write.jdbc(url=jdbcUrl, table=\"dbo.reservation\",mode = \"overwrite\", properties=connectionProperties )\nexcept ValueError as error :\n  print(\"Connector write failed\", error)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Writing data to relational database (SQL Server)","showTitle":true,"inputWidgets":{},"nuid":"0da58958-243b-43e7-8de6-fe7fcf1f68a5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Fylex","dashboards":[],"language":"python","widgets":{},"notebookOrigID":2618342201295270}},"nbformat":4,"nbformat_minor":0}
